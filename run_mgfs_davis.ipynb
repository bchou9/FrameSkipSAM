{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc92286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 validation sequences\n"
     ]
    }
   ],
   "source": [
    "import sys, os, json, time, subprocess, pathlib\n",
    "from pathlib import Path\n",
    "from davis2017.davis import DAVIS\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "DAVIS_ROOT  = Path(\"./data/davis/DAVIS\")          # ← adjust\n",
    "OUT_DIR     = Path(\"./data/sam2_preds\")     # where we’ll save PNGs\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# DAVIS helper (semi-supervised = first-frame GT mask)\n",
    "ds = DAVIS(str(DAVIS_ROOT), task=\"semi-supervised\", subset=\"val\", resolution=\"480p\")\n",
    "print(f\"Loaded {len(ds.sequences)} validation sequences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302a2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "sam2_checkpoint = \"./checkpoints/sam2.1_hiera_large.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "\n",
    "predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4bb2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_mask(mask, ax, obj_id=None, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"tab10\")\n",
    "        cmap_idx = 0 if obj_id is None else obj_id\n",
    "        color = np.array([*cmap(cmap_idx)[:3], 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def run_sequence(seq_name: str) -> float:\n",
    "    img_dir = Path(ds.sequences[seq_name]['images'][0]).parent\n",
    "    inference_state   = predictor.init_state(str(img_dir))\n",
    "    predictor.reset_state(inference_state)\n",
    "\n",
    "    # --- first-frame GT mask (ensure 2-D) ---\n",
    "    first_gt = iio.imread(ds.sequences[seq_name]['masks'][0])\n",
    "    if first_gt.ndim == 3:          # palette PNG → RGB/RGBA\n",
    "        first_gt = first_gt[..., 0]\n",
    "\n",
    "    for k in range(1, int(first_gt.max()) + 1):\n",
    "        predictor.add_new_mask(\n",
    "            inference_state,\n",
    "            frame_idx=0,\n",
    "            obj_id=f\"obj-{k}\",\n",
    "            mask=(first_gt == k).astype(\"uint8\"),\n",
    "        )\n",
    "\n",
    "    # --- propagate & save ---\n",
    "    t0 = time.time()\n",
    "    n_frames = len(ds.sequences[seq_name]['images'])\n",
    "    # run propagation throughout the video and collect the results in a dict\n",
    "    video_segments = {}  # video_segments contains the per-frame segmentation results\n",
    "    for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):\n",
    "        video_segments[out_frame_idx] = {\n",
    "            out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "            for i, out_obj_id in enumerate(out_obj_ids)\n",
    "        }\n",
    "        # # save the results to PNGs\n",
    "        # for out_obj_id, out_mask in video_segments[out_frame_idx].items():\n",
    "        #     out_mask = out_mask.astype(\"uint8\") * 255\n",
    "        #     out_path = OUT_DIR / f\"{seq_name}_{out_frame_idx:04d}_{out_obj_id}.png\"\n",
    "        #     iio.imwrite(out_path, out_mask)\n",
    "\n",
    "    vis_frame_stride = 1\n",
    "    plt.close(\"all\")\n",
    "    for out_frame_idx in range(0, len(n_frames), vis_frame_stride):\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.title(f\"frame {out_frame_idx}\")\n",
    "        plt.imshow(Image.open(ds.sequences[seq_name]['images'][out_frame_idx]))\n",
    "        for out_obj_id, out_mask in video_segments[out_frame_idx].items():\n",
    "            show_mask(out_mask, plt.gca(), obj_id=out_obj_id)\n",
    "\n",
    "    return n_frames / (time.time() - t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b365167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame loading (JPEG): 100%|██████████| 69/69 [00:01<00:00, 60.71it/s]\n",
      "/home/wei/FrameSkipSAM/sam2/sam2_video_predictor.py:878: UserWarning: cannot import name '_C' from 'sam2' (/home/wei/FrameSkipSAM/sam2/__init__.py)\n",
      "\n",
      "Skipping the post-processing step due to the error above. You can still use SAM 2 and it's OK to ignore the error above, although some post-processing functionality may be limited (which doesn't affect the results in most cases; see https://github.com/facebookresearch/sam2/blob/main/INSTALL.md).\n",
      "  pred_masks_gpu = fill_holes_in_mask_scores(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 1 due to low MAD (0.04)\n",
      "Skipping frame 2 due to low MAD (0.06)\n",
      "Skipping frame 3 due to low MAD (0.07)\n",
      "Skipping frame 4 due to low MAD (0.09)\n"
     ]
    }
   ],
   "source": [
    "fps_vals = {}\n",
    "for seq in tqdm(ds.get_sequences(), desc=\"SAM2 on DAVIS-val\"):\n",
    "    fps_vals[seq] = run_sequence(seq)\n",
    "\n",
    "print(f\"Mean FPS: {sum(fps_vals.values())/len(fps_vals):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
