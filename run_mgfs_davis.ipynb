{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc92286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 validation sequences\n"
     ]
    }
   ],
   "source": [
    "import sys, os, json, time, subprocess, pathlib\n",
    "from pathlib import Path\n",
    "from davis2017.davis import DAVIS\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "DAVIS_ROOT  = Path(\"./data/davis/DAVIS\")          # ← adjust\n",
    "OUT_DIR     = Path(\"./data/sam2_preds\")     # where we’ll save PNGs\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# DAVIS helper (semi-supervised = first-frame GT mask)\n",
    "ds = DAVIS(str(DAVIS_ROOT), task=\"semi-supervised\", subset=\"val\", resolution=\"480p\")\n",
    "print(f\"Loaded {len(ds.sequences)} validation sequences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302a2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "sam2_checkpoint = \"./checkpoints/sam2.1_hiera_large.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "\n",
    "predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_mask(mask, ax, obj_id=None, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"tab10\")\n",
    "        cmap_idx = 0 if obj_id is None else obj_id\n",
    "        color = np.array([*cmap(cmap_idx)[:3], 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def run_sequence(seq_name: str) -> float:\n",
    "    img_dir = Path(ds.sequences[seq_name]['images'][0]).parent\n",
    "    inference_state   = predictor.init_state(str(img_dir))\n",
    "    predictor.reset_state(inference_state)\n",
    "\n",
    "    # --- first-frame GT mask (ensure 2-D) ---\n",
    "    first_gt = iio.imread(ds.sequences[seq_name]['masks'][0])\n",
    "    if first_gt.ndim == 3:          # palette PNG → RGB/RGBA\n",
    "        first_gt = first_gt[..., 0]\n",
    "\n",
    "    for k in range(1, int(first_gt.max()) + 1):\n",
    "        predictor.add_new_mask(\n",
    "            inference_state,\n",
    "            frame_idx=0,\n",
    "            obj_id=f\"obj-{k}\",\n",
    "            mask=(first_gt == k).astype(\"uint8\"),\n",
    "        )\n",
    "\n",
    "    # --- propagate & save ---\n",
    "    t0 = time.time()\n",
    "    n_frames = len(ds.sequences[seq_name]['images'])\n",
    "    # run propagation throughout the video and collect the results in a dict\n",
    "    video_segments = {}  # video_segments contains the per-frame segmentation results\n",
    "    for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):\n",
    "        video_segments[out_frame_idx] = {\n",
    "            out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "            for i, out_obj_id in enumerate(out_obj_ids)\n",
    "        }\n",
    "        # # save the results to PNGs\n",
    "        # for out_obj_id, out_mask in video_segments[out_frame_idx].items():\n",
    "        #     out_mask = out_mask.astype(\"uint8\") * 255\n",
    "        #     out_path = OUT_DIR / f\"{seq_name}_{out_frame_idx:04d}_{out_obj_id}.png\"\n",
    "        #     iio.imwrite(out_path, out_mask)\n",
    "\n",
    "    vis_frame_stride = 1\n",
    "    plt.close(\"all\")\n",
    "    for out_frame_idx in range(0, n_frames, vis_frame_stride):\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.title(f\"frame {out_frame_idx}\")\n",
    "        plt.imshow(Image.open(ds.sequences[seq_name]['images'][out_frame_idx]))\n",
    "        for out_obj_id, out_mask in video_segments[out_frame_idx].items():\n",
    "            show_mask(out_mask, plt.gca(), obj_id=out_obj_id)\n",
    "\n",
    "    return n_frames / (time.time() - t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b365167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame loading (JPEG): 100%|██████████| 69/69 [00:01<00:00, 60.71it/s]\n",
      "/home/wei/FrameSkipSAM/sam2/sam2_video_predictor.py:878: UserWarning: cannot import name '_C' from 'sam2' (/home/wei/FrameSkipSAM/sam2/__init__.py)\n",
      "\n",
      "Skipping the post-processing step due to the error above. You can still use SAM 2 and it's OK to ignore the error above, although some post-processing functionality may be limited (which doesn't affect the results in most cases; see https://github.com/facebookresearch/sam2/blob/main/INSTALL.md).\n",
      "  pred_masks_gpu = fill_holes_in_mask_scores(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 1 due to low MAD (0.04)\n",
      "Skipping frame 2 due to low MAD (0.06)\n",
      "Skipping frame 3 due to low MAD (0.07)\n",
      "Skipping frame 4 due to low MAD (0.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 6 due to low MAD (0.07)\n",
      "Skipping frame 7 due to low MAD (0.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 9 due to low MAD (0.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 13 due to low MAD (0.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 15 due to low MAD (0.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 17 due to low MAD (0.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 23 due to low MAD (0.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 26 due to low MAD (0.08)\n",
      "Skipping frame 27 due to low MAD (0.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 29 due to low MAD (0.04)\n",
      "Skipping frame 30 due to low MAD (0.05)\n",
      "Avg FPS last 30 frames: 0.26\n",
      "Skipping frame 31 due to low MAD (0.05)\n",
      "Skipping frame 32 due to low MAD (0.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 33 due to low MAD (0.08)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 35 due to low MAD (0.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 37 due to low MAD (0.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 44 due to low MAD (0.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 55 due to low MAD (0.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 57 due to low MAD (0.08)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg FPS last 30 frames: 0.18\n",
      "Skipping frame 61 due to low MAD (0.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 63 due to low MAD (0.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 65 due to low MAD (0.07)\n",
      "Skipping frame 66 due to low MAD (0.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "propagate in video: 100%|██████████| 69/69 [04:58<00:00,  4.33s/it]\n",
      "SAM2 on DAVIS-val: 0it [05:02, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping frame 68 due to low MAD (0.04)\n",
      "Skipped 28 frames due to low MAD.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m fps_vals = {}\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m tqdm(ds.get_sequences(), desc=\u001b[33m\"\u001b[39m\u001b[33mSAM2 on DAVIS-val\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     fps_vals[seq] = \u001b[43mrun_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMean FPS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(fps_vals.values())/\u001b[38;5;28mlen\u001b[39m(fps_vals)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mrun_sequence\u001b[39m\u001b[34m(seq_name)\u001b[39m\n\u001b[32m     48\u001b[39m vis_frame_stride = \u001b[32m1\u001b[39m\n\u001b[32m     49\u001b[39m plt.close(\u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m out_frame_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_frames\u001b[49m\u001b[43m)\u001b[49m, vis_frame_stride):\n\u001b[32m     51\u001b[39m     plt.figure(figsize=(\u001b[32m6\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m     52\u001b[39m     plt.title(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mframe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_frame_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "fps_vals = {}\n",
    "for seq in tqdm(ds.get_sequences(), desc=\"SAM2 on DAVIS-val\"):\n",
    "    fps_vals[seq] = run_sequence(seq)\n",
    "\n",
    "print(f\"Mean FPS: {sum(fps_vals.values())/len(fps_vals):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
